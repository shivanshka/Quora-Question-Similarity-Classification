{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7052fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistance\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distance'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from os import path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "598872d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distance\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "Building wheels for collected packages: distance\n",
      "  Building wheel for distance (setup.py): started\n",
      "  Building wheel for distance (setup.py): finished with status 'done'\n",
      "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16276 sha256=ee990ef928b89c53cd3282b065fa8c43d14b3f853584f5492cdecfd25f86ea84\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\fb\\b3\\aa\\04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
      "Successfully built distance\n",
      "Installing collected packages: distance\n",
      "Successfully installed distance-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd5b16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.read_csv(\"../data/pred_data20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ebab308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6028</td>\n",
       "      <td>11823</td>\n",
       "      <td>11824</td>\n",
       "      <td>Who is the most powerful person in earth and why?</td>\n",
       "      <td>Who actually is the most powerful person or wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139097</td>\n",
       "      <td>23573</td>\n",
       "      <td>34861</td>\n",
       "      <td>How can I make a suicide look like an accident?</td>\n",
       "      <td>How do I die and make it look like an accident?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29616</td>\n",
       "      <td>54775</td>\n",
       "      <td>54776</td>\n",
       "      <td>Which Jedi Knights used red-colored lightsabers?</td>\n",
       "      <td>Who was the first Jedi Knight?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160739</td>\n",
       "      <td>68835</td>\n",
       "      <td>250621</td>\n",
       "      <td>What is the quickest way to make $8,000?</td>\n",
       "      <td>What are the quickest ways to make money?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354430</td>\n",
       "      <td>99603</td>\n",
       "      <td>483552</td>\n",
       "      <td>What are some good deodorants and perfumes for...</td>\n",
       "      <td>What is the average percentage of water that i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>281504</td>\n",
       "      <td>101771</td>\n",
       "      <td>30183</td>\n",
       "      <td>How can I come over borderline personality dis...</td>\n",
       "      <td>What is borderline personality disorder, and h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66640</td>\n",
       "      <td>115474</td>\n",
       "      <td>115475</td>\n",
       "      <td>If you could go back in time and give your you...</td>\n",
       "      <td>If you could go back in time, what advice woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130187</td>\n",
       "      <td>117142</td>\n",
       "      <td>50267</td>\n",
       "      <td>What are the best new products in technology t...</td>\n",
       "      <td>What are some mind blowing gadgets that exist ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78043</td>\n",
       "      <td>133143</td>\n",
       "      <td>133144</td>\n",
       "      <td>How do I impress a girl whom I like?</td>\n",
       "      <td>How do I impress the girl on whom I have a crush?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78842</td>\n",
       "      <td>134351</td>\n",
       "      <td>134352</td>\n",
       "      <td>Are sex and love different?</td>\n",
       "      <td>Is sex and love different?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>167098</td>\n",
       "      <td>249691</td>\n",
       "      <td>259127</td>\n",
       "      <td>What are some good online courses to learn for...</td>\n",
       "      <td>What are some good websites to learn foreign l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>163735</td>\n",
       "      <td>254604</td>\n",
       "      <td>102921</td>\n",
       "      <td>How is Darwin's theory different from Lamarck'...</td>\n",
       "      <td>What are the similarities between Darwin's The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>167121</td>\n",
       "      <td>259157</td>\n",
       "      <td>259158</td>\n",
       "      <td>How many dollars will a German earn as a fresh...</td>\n",
       "      <td>Which are the good hotels to stay in Bhuj or K...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>172625</td>\n",
       "      <td>266489</td>\n",
       "      <td>266490</td>\n",
       "      <td>What do feminists think of the relationship be...</td>\n",
       "      <td>A girl compared my personality to the lead cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>182251</td>\n",
       "      <td>278989</td>\n",
       "      <td>278990</td>\n",
       "      <td>Why do some people prefer the .45 over the 9mm?</td>\n",
       "      <td>What is the lightest, flattest 9mm pistol avai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>203580</td>\n",
       "      <td>306241</td>\n",
       "      <td>306242</td>\n",
       "      <td>Is there any way to differentiate between nucl...</td>\n",
       "      <td>In a war between Russia and the US, is there a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>397023</td>\n",
       "      <td>313164</td>\n",
       "      <td>530128</td>\n",
       "      <td>What kinds of food do you like to eat?</td>\n",
       "      <td>What kind of snacks do you like to eat?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>268520</td>\n",
       "      <td>386083</td>\n",
       "      <td>386084</td>\n",
       "      <td>Which are the university in Germany to study i...</td>\n",
       "      <td>Can you suggest some universities for MS in au...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>365285</td>\n",
       "      <td>495390</td>\n",
       "      <td>495391</td>\n",
       "      <td>What are some good technical petroleum books f...</td>\n",
       "      <td>What are some good technical books about petro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>398381</td>\n",
       "      <td>531600</td>\n",
       "      <td>68478</td>\n",
       "      <td>How are stock prices adjusted?</td>\n",
       "      <td>How do I find stock prices?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    qid1    qid2                                          question1  \\\n",
       "0     6028   11823   11824  Who is the most powerful person in earth and why?   \n",
       "1   139097   23573   34861    How can I make a suicide look like an accident?   \n",
       "2    29616   54775   54776   Which Jedi Knights used red-colored lightsabers?   \n",
       "3   160739   68835  250621           What is the quickest way to make $8,000?   \n",
       "4   354430   99603  483552  What are some good deodorants and perfumes for...   \n",
       "5   281504  101771   30183  How can I come over borderline personality dis...   \n",
       "6    66640  115474  115475  If you could go back in time and give your you...   \n",
       "7   130187  117142   50267  What are the best new products in technology t...   \n",
       "8    78043  133143  133144               How do I impress a girl whom I like?   \n",
       "9    78842  134351  134352                        Are sex and love different?   \n",
       "10  167098  249691  259127  What are some good online courses to learn for...   \n",
       "11  163735  254604  102921  How is Darwin's theory different from Lamarck'...   \n",
       "12  167121  259157  259158  How many dollars will a German earn as a fresh...   \n",
       "13  172625  266489  266490  What do feminists think of the relationship be...   \n",
       "14  182251  278989  278990    Why do some people prefer the .45 over the 9mm?   \n",
       "15  203580  306241  306242  Is there any way to differentiate between nucl...   \n",
       "16  397023  313164  530128             What kinds of food do you like to eat?   \n",
       "17  268520  386083  386084  Which are the university in Germany to study i...   \n",
       "18  365285  495390  495391  What are some good technical petroleum books f...   \n",
       "19  398381  531600   68478                     How are stock prices adjusted?   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "0   Who actually is the most powerful person or wh...             1  \n",
       "1     How do I die and make it look like an accident?             1  \n",
       "2                     Who was the first Jedi Knight?              0  \n",
       "3           What are the quickest ways to make money?             1  \n",
       "4   What is the average percentage of water that i...             0  \n",
       "5   What is borderline personality disorder, and h...             1  \n",
       "6   If you could go back in time, what advice woul...             1  \n",
       "7   What are some mind blowing gadgets that exist ...             1  \n",
       "8   How do I impress the girl on whom I have a crush?             1  \n",
       "9                          Is sex and love different?             1  \n",
       "10  What are some good websites to learn foreign l...             0  \n",
       "11  What are the similarities between Darwin's The...             1  \n",
       "12  Which are the good hotels to stay in Bhuj or K...             0  \n",
       "13  A girl compared my personality to the lead cha...             0  \n",
       "14  What is the lightest, flattest 9mm pistol avai...             0  \n",
       "15  In a war between Russia and the US, is there a...             0  \n",
       "16            What kind of snacks do you like to eat?             0  \n",
       "17  Can you suggest some universities for MS in au...             0  \n",
       "18  What are some good technical books about petro...             1  \n",
       "19                        How do I find stock prices?             0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1703d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pred_data.iloc[:,:-1]\n",
    "y_pred = pred_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42329f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path:str):\n",
    "    with open(model_path, \"rb\") as m:\n",
    "        model = pickle.load(m)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a672cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model(\"../Models/xgboost4_calibrated.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['freq_qid1'] = data.groupby('qid1')['qid1'].transform('count')\n",
    "data['freq_qid2'] = data.groupby('qid2')['qid2'].transform('count')\n",
    "data['q1len'] = data['question1'].str.len()\n",
    "data['q2len'] = data['question2'].str.len()\n",
    "data['q1_n_words'] = data['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "data['q2_n_words'] = data['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "\n",
    "def normalized_word_Common(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return 1.0 * len(w1 & w2)\n",
    "data['word_Common'] = data.apply(normalized_word_Common, axis=1)\n",
    "\n",
    "def normalized_word_Total(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return 1.0*(len(w1) + len(w2))\n",
    "data['word_Total'] = data.apply(normalized_word_Total, axis=1)\n",
    "\n",
    "def normalized_word_share(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "\n",
    "data['word_share'] = data.apply(normalized_word_share, axis=1)\n",
    "data['freq_q1+q2'] = data['freq_qid1'] + data['freq_qid2']\n",
    "data['freq_q1-q2'] = abs(data['freq_qid1'] - data['freq_qid2'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636046cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAFE_DIV = 0.0001 # to get result in 4 decimal points\n",
    "\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    pattern = re.compile('\\W')\n",
    "\n",
    "    if type(x) == type(''):\n",
    "        x = re.sub(pattern,' ',x)\n",
    "\n",
    "    if type(x) == type(''):\n",
    "        x = porter.stem(x)\n",
    "        example1 = BeautifulSoup(x)\n",
    "        x = example1.get_text()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09db733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "\n",
    "    # Converting questions into tokens\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens)== 0 or len(q2_tokens)==0:\n",
    "        return token_features\n",
    "\n",
    "    # Getting non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOPWORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOPWORDS])\n",
    "\n",
    "    # Getting stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOPWORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOPWORDS])\n",
    "\n",
    "    # Getting the common non-stopwords from questions pair\n",
    "    common_word_count = len(set(q1_words).intersection(set(q2_words)))\n",
    "\n",
    "    # Getting the common stopwords from questions pair\n",
    "    common_stop_count = len(set(q1_stops).intersection(set(q2_stops)))\n",
    "\n",
    "    # Getting the common non-stopwords from questions pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "\n",
    "    # Last word of both questions is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "\n",
    "    # First word of both questions is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "\n",
    "    # Average token length of both Questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "\n",
    "    return token_features\n",
    "\n",
    "def get_longest_substr_ratio(a,b):\n",
    "    strs = list(distance.lcsubstrings(a,b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b))+1)\n",
    "\n",
    "def extract_features(df):\n",
    "    # preprocessing each question\n",
    "    df['question1'] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df['question2'] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"Token features..........\")\n",
    "\n",
    "    # Merging features with dataset\n",
    "    token_features = df.apply(lambda x: get_token_features(x['question1'], x['question2']), axis=1)\n",
    "\n",
    "    df[\"cwc_min\"]       = list(map(lambda x:x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x:x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x:x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x:x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x:x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x:x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x:x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x:x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x:x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x:x[9], token_features))\n",
    "\n",
    "    ## Computing fuzzy features\n",
    "    print(\"Fuzzy Features........\")\n",
    "\n",
    "    df['token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(x['question1'], x['question2']),axis=1)\n",
    "    df['token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(x['question1'], x['question2']),axis=1)\n",
    "    df['fuzz_ratio'] = df.apply(lambda x: fuzz.QRatio(x['question1'], x['question2']),axis=1)\n",
    "    df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(x['question1'], x['question2']),axis=1)\n",
    "    df['longest_substr_ratio'] = df.apply(lambda x: get_longest_substr_ratio(x['question1'], x['question2']),axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "stopwords.add(\"said\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\" \")\n",
    "stopwords.remove(\"not\")\n",
    "stopwords.remove(\"no\")\n",
    "stopwords.remove(\"like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2tfidf = pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "vecs1 = []\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1)\n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)]) \n",
    "\n",
    "    for word1 in doc1:\n",
    "        vec1 = word1.vector\n",
    "\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        mean_vec1 += vec1*idf\n",
    "\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "df[\"q1_feats_m\"] = list(vecs1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593aa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
